{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "user = os.getenv('ANALYTIC_DB_USERNAME')\n",
    "password = os.getenv('ANALYTIC_DB_PASSWORD')\n",
    "host = os.getenv('ANALYTIC_DB_HOSTNAME')\n",
    "db = os.getenv('ANALYTIC_DB_DATABASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectionString = 'postgresql+psycopg2://{}:{}@{}:5432/{}'.format(user, password, host, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(connectionString)\n",
    "print(f'{connectionString} Connected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select json_array_elements(details->'images')->>'caption' as caption, json_array_elements(details->'images')->>'thumbnailUrl' as image from eps_properties where details is not null and details->'images' is not null limit 200000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_models = pd.read_sql(query, con=conn)\n",
    "sql_reader = pd.read_sql(query, engine, chunksize=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist=not os.path.exists('images.csv')\n",
    "with open('images.csv', 'a', newline='\\n') as f:\n",
    "    for chunk in sql_reader:\n",
    "        chunk['caption']=chunk['caption'].str.lower()\n",
    "        chunk.to_csv(f, header=exist, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = False\n",
    "if os.path.exists('images.csv'):\n",
    "    csv_data = \\\n",
    "        pd.read_csv('images.csv', usecols=['caption', 'image'], \\\n",
    "                    dtype= { \"caption\": np.character, \"image\":np.character}, encoding='latin1')\n",
    "    preprocessed_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = csv_data[pd.notnull(csv_data['caption'])]\n",
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaces = {'/' : '_', ' ' : '_'}\n",
    "csv_data['caption']=csv_data['caption'].str.translate(str.maketrans(replaces))\n",
    "captions = set()\n",
    "captions.update(csv_data['caption'].unique())\n",
    "captions=sorted(captions)\n",
    "print(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.to_csv('./hotel_images/images.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, caption in enumerate(captions):\n",
    "    print(\"index is %d and value is %s\" % (idx, caption))\n",
    "    Path('./hotel_images/train/' + caption).mkdir(parents=True, exist_ok=True)\n",
    "    Path('./hotel_images/test/' + caption).mkdir(parents=True, exist_ok=True)\n",
    "    Path('./hotel_images/valid/' + caption).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState = RandomState()\n",
    "train_data = csv_data.sample(frac=0.6, random_state=randomState)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_than_train_data = csv_data.loc[~csv_data.index.isin(train_data.index)]\n",
    "other_than_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = other_than_train_data.sample(frac=0.5, random_state=randomState)\n",
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = other_than_train_data.loc[~other_than_train_data.index.isin(validation_data.index)]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('./hotel_images/train/images.csv', index=False, encoding='utf-8')\n",
    "test_data.to_csv('./hotel_images/test/images.csv', index=False, encoding='utf-8')\n",
    "validation_data.to_csv('./hotel_images/valid/images.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please clean up all the code below this as download_images.py is the lasted tool to download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(group_type):\n",
    "    return \\\n",
    "        pd.read_csv('./hotel_images/'+group_type+'/images.csv', usecols=['caption', 'image'], \\\n",
    "                    dtype= { \"caption\": np.character, \"image\":np.character}, \\\n",
    "                    encoding='utf-8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data('train')\n",
    "test_data = load_data('test')\n",
    "validation_data = load_data('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_photo(img_url, group_type, category, filename):\n",
    "    try:\n",
    "        file_path = \"./hotelImages/%s/%s/%s\" % (group_type, category, filename)\n",
    "        print(file_path)\n",
    "        urlretrieve(img_url, file_path)\n",
    "    except:\n",
    "        print(img_url)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[train_data['image']!='image']\n",
    "test_data=test_data[test_data['image']!='image']\n",
    "validation_data=validation_data[validation_data['image']!='image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_data.iterrows():\n",
    "    image_name = row['image'].rsplit('/', 1)\n",
    "    if len(image_name)<2:\n",
    "        print(row['image'])\n",
    "#         break\n",
    "#     file_name = \"%d.%s\" % (index, image_name[1])\n",
    "#     file_path = \"./hotelImages/%s/%s/%s\" % ('train', row['caption'], file_name)\n",
    "#     print(file_path)\n",
    "#     urlretrieve('http:' + row['image'], file_path)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm, tqdm_notebook\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_image_of(row, group):\n",
    "#     image_name = row['image'].rsplit('/', 1)\n",
    "#     download_photo(img_url='http:' + row['image'], group_type=group, category=row['caption'], filename= image_name[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size = int(test_data.shape[0]/4)\n",
    "# chunks = [test_data.ix[test_data.index[i:i + chunk_size]] for i in range(0, test_data.shape[0], chunk_size)]\n",
    "# pool = Pool(4)\n",
    "# result = pool.map(func, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_photo_row(index, row):\n",
    "    image_name = row['image'].rsplit('/', 1)\n",
    "    return download_photo(img_url='http:' + row['image'], group_type='valid', category=row['caption'], filename= \"%d.%s\" % (index, image_name[1]))\n",
    "\n",
    "def progressive_download_photo(pbar, index, row):\n",
    "    download_photo_row(index, row)\n",
    "    pbar.update(1)\n",
    "    \n",
    "def progressive_download_test2(index, row, p):\n",
    "    print(index)\n",
    "    pbar.update(1)    \n",
    "    return index\n",
    "\n",
    "def progressive_download_test(pbar, index, row):\n",
    "    pbar.update(1)    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://leimao.github.io/blog/Python-tqdm-Multiprocessing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "pool = mp.Pool(processes=(mp.cpu_count()-2))\n",
    "tqdm.pandas(desc=\"processing in progress ... %d\" %(mp.cpu_count()))\n",
    "\n",
    "with tqdm(total=len(list(validation_data.iterrows()))) as pbar:\n",
    "    download_row = partial(progressive_download_test2, p=pbar)\n",
    "    pool.map( download_row, [(index, row) for index, row in validation_data.head(10).iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "pool = mp.Pool(processes=(mp.cpu_count()-2))\n",
    "tqdm.pandas(desc=\"processing in progress ... %d\" %(mp.cpu_count()))\n",
    "\n",
    "with tqdm(total=len(list(validation_data.iterrows()))) as pbar:\n",
    "    download_row = partial(progressive_download_photo, pbar)\n",
    "    pool.map( download_row, [(index, row) for index, row in validation_data.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"processing in progress ...\")\n",
    "\n",
    "with tqdm(total=len(list(validation_data.iterrows()))) as pbar:\n",
    "    for index, row in validation_data.iterrows():\n",
    "        image_name = row['image'].rsplit('/', 1)\n",
    "        download_photo(img_url='http:' + row['image'], group_type='valid', category=row['caption'], filename= \"%d.%s\" % (index, image_name[1]))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas(desc=\"processing in progress ...\")\n",
    "\n",
    "# train_data.progress_apply(lambda row: download_photo(img_url='http:' + row['image'], group_type='test', category=row['caption'], filename= row['image'].rsplit('/', 1)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.progress_apply(lambda x: download_image_of(x, 'train'))\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "    image_name = row['image'].rsplit('/', 1)\n",
    "    download_photo(img_url='http:' + row['image'], group_type='test', category=row['caption'], filename= \"%d.%s\" % (index, image_name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reoganize folders\n",
    "\n",
    "Collect all folders with more than 100 images to category_images directory and the rest of the images are put under unknown category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "import os, csv\n",
    "from pathlib import Path\n",
    "\n",
    "    \n",
    "path_keys = ['valid','train','test']\n",
    "\n",
    "def scan_file_count(path_key, image_dict):  \n",
    "    path = './hotel_images/' + path_key + '/'\n",
    "    current_dict = {}\n",
    "    for root, dirs, _ in os.walk(path):\n",
    "        for d in dirs:\n",
    "            a = str(d)\n",
    "            current_dir = path + a\n",
    "            count = int(len([name for name in os.listdir(current_dir) if os.path.isfile(os.path.join(current_dir, name))]))\n",
    "            current_dict = image_dict.get(a)\n",
    "            if current_dict == None :\n",
    "                current_dict = {'name': a}\n",
    "                image_dict[a] = current_dict\n",
    "            current_dict[path_key]=count\n",
    "            \n",
    "def valid_category(item, path_keys):\n",
    "    for path_key in path_keys:\n",
    "        count = int(item.get(path_key))\n",
    "        if count<100 :\n",
    "            print(path_key, count, False)\n",
    "            return count\n",
    "    print(path_key, count, True)\n",
    "    return count\n",
    "\n",
    "def new_file_name(src_file):\n",
    "    pieces = str(src_file).split('\\\\')\n",
    "    length =len(pieces)\n",
    "    if length < 2:\n",
    "        return None\n",
    "    return pieces[len(pieces)-2] + '_' + pieces[len(pieces)-1]\n",
    "   \n",
    "    \n",
    "def copy_category(item, path_keys, count):\n",
    "    fromBaseDirectory = './hotel_images/'\n",
    "    toDirectory = './category_images/'\n",
    "    for path_key in path_keys:\n",
    "        fromDirectory=fromBaseDirectory+path_key+'/'+item.get('name')\n",
    "        if count > 100:\n",
    "            print(fromDirectory, toDirectory+path_key+'/'+item.get('name'))\n",
    "            copy_tree(fromDirectory, toDirectory+path_key+'/'+item.get('name'))\n",
    "        elif count > 0:\n",
    "            print(fromDirectory, toDirectory+path_key+'/unknown')\n",
    "            copy_tree(fromDirectory, toDirectory+path_key+'/unknown')\n",
    "#             for src_file in Path(fromDirectory).glob('*.jpg'):\n",
    "#                  if os.path.isfile(src_file):\n",
    "#                     out_file_name = new_file_name(src_file)\n",
    "#                     if out_file_name is None:\n",
    "#                         continue\n",
    "#                     print(toDirectory+path_key+'/unknown/'+out_file_name)\n",
    "#                     shutil.copy2(src_file, toDirectory+path_key+'/unknown/'+out_file_name)\n",
    "        else:\n",
    "            print(fromDirectory+path_key+'/'+item.get('name'), 'no copy')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {}\n",
    "for path_key in path_keys:\n",
    "    scan_file_count(path_key, image_dict)\n",
    "\n",
    "values = image_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname('./category_images/valid/unknown/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('./category_images/train/unknown/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname('./category_images/test/unknown/'), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = ['name','valid','train','test']\n",
    "print('./image_num.csv')\n",
    "with open('./image_num.csv', 'w', encoding='utf-8', newline='')  as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, fieldnames=csv_columns)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(values)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, value in enumerate(values):\n",
    "    copy_category(value, path_keys, valid_category(value, path_keys))\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
