{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sqlalchemy\n",
    "# !pip install python-dotenv\n",
    "# !pip install psycopg2\n",
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "user = os.getenv('HS_DB_USERNAME')\n",
    "password = os.getenv('HS_DB_PASSWORD')\n",
    "host = os.getenv('HS_DB_HOSTNAME')\n",
    "db = os.getenv('HS_DB_DATABASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectionString = 'postgresql+psycopg2://{}:{}@{}:5432/{}'.format(user, password, host, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(connectionString)\n",
    "print(f'{connectionString} Connected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line is to select the image url from the our database. 'thumbnailUrl' is the small image 70x70. Now we are trying to see if the bigger image can help improve the training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select json_array_elements(details->'images')->>'caption' as caption, json_array_elements(details->'images')->>'thumbnailUrl' as image from eps_properties where details is not null and details->'images' is not null limit 200000\"\n",
    "query = \"select json_array_elements(details->'images')->>'caption' as caption, json_array_elements(details->'images')->>'url' as image from eps_properties where details is not null and details->'images' is not null limit 20000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_models = pd.read_sql(query, con=conn)\n",
    "sql_reader = pd.read_sql(query, engine, chunksize=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_csv_out = 'images.csv'\n",
    "image_base_path = './m_images/'\n",
    "if not os.path.exists(image_base_path):\n",
    "    os.makedirs(image_base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# image_base_path = './hotel_images/'\n",
    "exist=not os.path.exists(image_csv_out)\n",
    "with open(image_csv_out, 'a', newline='\\n') as f:\n",
    "    for chunk in sql_reader:\n",
    "        chunk['caption']=chunk['caption'].str.lower()\n",
    "        chunk.to_csv(f, header=exist, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = False\n",
    "if os.path.exists(image_csv_out):\n",
    "    csv_data = \\\n",
    "        pd.read_csv(image_csv_out, usecols=['caption', 'image'], \\\n",
    "                    dtype= { \"caption\": np.character, \"image\":np.character}, encoding='latin1')\n",
    "    preprocessed_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = csv_data[pd.notnull(csv_data['caption'])]\n",
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaces = {'/' : '_', ' ' : '_'}\n",
    "csv_data['caption']=csv_data['caption'].str.translate(str.maketrans(replaces))\n",
    "captions = set()\n",
    "captions.update(csv_data['caption'].unique())\n",
    "captions=sorted(captions)\n",
    "print(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.to_csv(image_base_path+image_csv_out, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup training, test and valid directories to be used to store corresponding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, caption in enumerate(captions):\n",
    "    print(\"index is %d and value is %s\" % (idx, caption))\n",
    "    Path(image_base_path+'train/' + caption).mkdir(parents=True, exist_ok=True)\n",
    "    Path(image_base_path+'test/' + caption).mkdir(parents=True, exist_ok=True)\n",
    "    Path(image_base_path+'valid/' + caption).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState = RandomState()\n",
    "train_data = csv_data.sample(frac=0.6, random_state=randomState)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_than_train_data = csv_data.loc[~csv_data.index.isin(train_data.index)]\n",
    "other_than_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = other_than_train_data.sample(frac=0.5, random_state=randomState)\n",
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = other_than_train_data.loc[~other_than_train_data.index.isin(validation_data.index)]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(image_base_path+'train/images.csv', index=False, encoding='utf-8')\n",
    "test_data.to_csv(image_base_path+'test/images.csv', index=False, encoding='utf-8')\n",
    "validation_data.to_csv(image_base_path+'valid/images.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download_images.py is the lasted tool to download images\n",
    "\n",
    "Now we need to use download_images.py to download all the images as specified in the images.csv under each prepared directory.\n",
    "The script has to be run using command prompt due to its asyn processing which can't be run with notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://leimao.github.io/blog/Python-tqdm-Multiprocessing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reoganize folders\n",
    "\n",
    "Collect all folders with more than 100 images to category_images directory and the rest of the images are put under unknown category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "import os, csv\n",
    "from pathlib import Path\n",
    "\n",
    "image_base_path = './m_images/'  \n",
    "image_cat_path = './category_m_images/'\n",
    "path_keys = ['valid','train','test']\n",
    "VALID_COUNT = 100\n",
    "\n",
    "def scan_file_count(path_key, image_dict):  \n",
    "    path = image_base_path + path_key + '/'\n",
    "    current_dict = {}\n",
    "    for root, dirs, _ in os.walk(path):\n",
    "        for d in dirs:\n",
    "            a = str(d)\n",
    "            current_dir = path + a\n",
    "            count = int(len([name for name in os.listdir(current_dir) if os.path.isfile(os.path.join(current_dir, name))]))\n",
    "            current_dict = image_dict.get(a)\n",
    "            if current_dict == None :\n",
    "                current_dict = {'name': a}\n",
    "                image_dict[a] = current_dict\n",
    "            current_dict[path_key]=count\n",
    "            \n",
    "def valid_category(item, path_keys):\n",
    "    for path_key in path_keys:\n",
    "        count = int(item.get(path_key))\n",
    "        if count<VALID_COUNT :\n",
    "#             print(path_key, count, False)\n",
    "            return count\n",
    "#     print(path_key, count, True)\n",
    "    return count\n",
    "\n",
    "def new_file_name(src_file):\n",
    "    pieces = str(src_file).split('\\\\')\n",
    "    length =len(pieces)\n",
    "    if length < 2:\n",
    "        return None\n",
    "    return pieces[len(pieces)-2] + '_' + pieces[len(pieces)-1]\n",
    "   \n",
    "def destination_file(src_file):\n",
    "    pieces = str(src_file).split('\\\\')\n",
    "    length =len(pieces)\n",
    "    if length < 2:\n",
    "        return None\n",
    "    return pieces[len(pieces)-1]\n",
    "    \n",
    "def copy_category(item, path_keys, count):\n",
    "    fromBaseDirectory = image_base_path\n",
    "    toDirectory = image_cat_path\n",
    "    for path_key in path_keys:\n",
    "        fromDirectory=fromBaseDirectory+path_key+'/'+item.get('name')\n",
    "        if count > VALID_COUNT:\n",
    "            print(fromDirectory, toDirectory+path_key+'/'+item.get('name'))\n",
    "            copy_tree(fromDirectory, toDirectory+path_key+'/'+item.get('name'))\n",
    "        elif count > 0:\n",
    "            print(fromDirectory, toDirectory+path_key+'/unknown')\n",
    "            copy_tree(fromDirectory, toDirectory+path_key+'/unknown')\n",
    "#             for src_file in Path(fromDirectory).glob('*.jpg'):\n",
    "#                  if os.path.isfile(src_file):\n",
    "#                     out_file_name = new_file_name(src_file)\n",
    "#                     if out_file_name is None:\n",
    "#                         continue\n",
    "#                     print(toDirectory+path_key+'/unknown/'+out_file_name)\n",
    "#                     shutil.copy2(src_file, toDirectory+path_key+'/unknown/'+out_file_name)\n",
    "        else:\n",
    "            print(fromDirectory+path_key+'/'+item.get('name'), 'no copy')\n",
    "        \n",
    "        \n",
    "def copy_category_with_same_image_count(item, path_keys, count, limit):\n",
    "    fromBaseDirectory = image_base_path\n",
    "    for path_key in path_keys:\n",
    "        fromDirectory=fromBaseDirectory+path_key+'/'+item.get('name')\n",
    "        if count > VALID_COUNT:\n",
    "            toDirectory = image_cat_path+path_key+'/'+item.get('name')+'/'\n",
    "            print(fromDirectory, toDirectory)\n",
    "            os.makedirs(os.path.dirname(toDirectory), exist_ok=True)\n",
    "            counter = 0\n",
    "            for src_file in Path(fromDirectory).glob('*.jpg'):\n",
    "                 if os.path.isfile(src_file):\n",
    "                    des_file = destination_file(src_file)\n",
    "                    if des_file is None:\n",
    "                        continue\n",
    "                    shutil.copy(src_file, toDirectory+des_file)\n",
    "                    counter = counter + 1\n",
    "                    if counter > limit:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dict = {}\n",
    "for path_key in path_keys:\n",
    "    scan_file_count(path_key, image_dict)\n",
    "\n",
    "values = image_dict.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If need unknow directory use the unknown lines below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.makedirs(os.path.dirname(image_cat_path+'/valid/unknown/'), exist_ok=True)\n",
    "# os.makedirs(os.path.dirname(image_cat_path+'/category_images/train/unknown/'), exist_ok=True)\n",
    "# os.makedirs(os.path.dirname(image_cat_path+'/test/unknown/'), exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.dirname(image_cat_path+'/valid/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(image_cat_path+'/train/'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(image_cat_path+'/test/'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_columns = ['name','valid','train','test']\n",
    "print('./m_image_num.csv')\n",
    "with open('./m_image_num.csv', 'w', encoding='utf-8', newline='')  as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, fieldnames=csv_columns)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(values)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, value in enumerate(values):\n",
    "#     copy_category(value, path_keys, valid_category(value, path_keys))\n",
    "    copy_category_with_same_image_count(value, path_keys, valid_category(value, path_keys), 100)\n",
    "#     print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}