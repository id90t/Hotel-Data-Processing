{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "from pathlib import Path\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tnrange, tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "user = os.getenv('ANALYTIC_DB_USERNAME')\n",
    "password = os.getenv('ANALYTIC_DB_PASSWORD')\n",
    "host = os.getenv('ANALYTIC_DB_HOSTNAME')\n",
    "db = os.getenv('ANALYTIC_DB_DATABASE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connectionString = 'postgresql+psycopg2://{}:{}@{}:5432/{}'.format(user, password, host, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(connectionString)\n",
    "print(f'{connectionString} Connected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select json_array_elements(details->'images')->>'caption' as caption, json_array_elements(details->'images')->>'thumbnailUrl' as image from eps_properties where details is not null and details->'images' is not null limit 200000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_models = pd.read_sql(query, con=conn)\n",
    "sql_reader = pd.read_sql(query, engine, chunksize=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist=not os.path.exists('images.csv')\n",
    "with open('images.csv', 'a', newline='\\n') as f:\n",
    "    for chunk in sql_reader:\n",
    "        chunk['caption']=chunk['caption'].str.lower()\n",
    "        chunk.to_csv(f, header=exist, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = False\n",
    "if os.path.exists('images.csv'):\n",
    "    csv_data = \\\n",
    "        pd.read_csv('images.csv', usecols=['caption', 'image'], \\\n",
    "                    dtype= { \"caption\": np.character, \"image\":np.character}, encoding='latin1')\n",
    "    preprocessed_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = csv_data[pd.notnull(csv_data['caption'])]\n",
    "csv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaces = {'/' : '_', ' ' : '_'}\n",
    "csv_data['caption']=csv_data['caption'].str.translate(str.maketrans(replaces))\n",
    "captions = set()\n",
    "captions.update(csv_data['caption'].unique())\n",
    "captions=sorted(captions)\n",
    "print(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.to_csv('./hotel_images/images.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, caption in enumerate(captions):\n",
    "    print(\"index is %d and value is %s\" % (idx, caption))\n",
    "    Path('./hotel_images/train/' + caption).mkdir(parents=True, exist_ok=True)\n",
    "    Path('./hotel_images/test/' + caption).mkdir(parents=True, exist_ok=True)\n",
    "    Path('./hotel_images/valid/' + caption).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState = RandomState()\n",
    "train_data = csv_data.sample(frac=0.6, random_state=randomState)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_than_train_data = csv_data.loc[~csv_data.index.isin(train_data.index)]\n",
    "other_than_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = other_than_train_data.sample(frac=0.5, random_state=randomState)\n",
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = other_than_train_data.loc[~other_than_train_data.index.isin(validation_data.index)]\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('./hotel_images/train/images.csv', index=False, encoding='utf-8')\n",
    "test_data.to_csv('./hotel_images/test/images.csv', index=False, encoding='utf-8')\n",
    "validation_data.to_csv('./hotel_images/valid/images.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please clean up all the code below this as download_images.py is the lasted tool to download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(group_type):\n",
    "    return \\\n",
    "        pd.read_csv('./hotel_images/'+group_type+'/images.csv', usecols=['caption', 'image'], \\\n",
    "                    dtype= { \"caption\": np.character, \"image\":np.character}, \\\n",
    "                    encoding='utf-8')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_data('train')\n",
    "test_data = load_data('test')\n",
    "validation_data = load_data('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_photo(img_url, group_type, category, filename):\n",
    "    try:\n",
    "        file_path = \"./hotelImages/%s/%s/%s\" % (group_type, category, filename)\n",
    "        print(file_path)\n",
    "        urlretrieve(img_url, file_path)\n",
    "    except:\n",
    "        print(img_url)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[train_data['image']!='image']\n",
    "test_data=test_data[test_data['image']!='image']\n",
    "validation_data=validation_data[validation_data['image']!='image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train_data.iterrows():\n",
    "    image_name = row['image'].rsplit('/', 1)\n",
    "    if len(image_name)<2:\n",
    "        print(row['image'])\n",
    "#         break\n",
    "#     file_name = \"%d.%s\" % (index, image_name[1])\n",
    "#     file_path = \"./hotelImages/%s/%s/%s\" % ('train', row['caption'], file_name)\n",
    "#     print(file_path)\n",
    "#     urlretrieve('http:' + row['image'], file_path)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tnrange, tqdm, tqdm_notebook\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def download_image_of(row, group):\n",
    "#     image_name = row['image'].rsplit('/', 1)\n",
    "#     download_photo(img_url='http:' + row['image'], group_type=group, category=row['caption'], filename= image_name[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_size = int(test_data.shape[0]/4)\n",
    "# chunks = [test_data.ix[test_data.index[i:i + chunk_size]] for i in range(0, test_data.shape[0], chunk_size)]\n",
    "# pool = Pool(4)\n",
    "# result = pool.map(func, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_photo_row(index, row):\n",
    "    image_name = row['image'].rsplit('/', 1)\n",
    "    return download_photo(img_url='http:' + row['image'], group_type='valid', category=row['caption'], filename= \"%d.%s\" % (index, image_name[1]))\n",
    "\n",
    "def progressive_download_photo(pbar, index, row):\n",
    "    download_photo_row(index, row)\n",
    "    pbar.update(1)\n",
    "    \n",
    "def progressive_download_test2(index, row, p):\n",
    "    print(index)\n",
    "    pbar.update(1)    \n",
    "    return index\n",
    "\n",
    "def progressive_download_test(pbar, index, row):\n",
    "    pbar.update(1)    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://leimao.github.io/blog/Python-tqdm-Multiprocessing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "pool = mp.Pool(processes=(mp.cpu_count()-2))\n",
    "tqdm.pandas(desc=\"processing in progress ... %d\" %(mp.cpu_count()))\n",
    "\n",
    "with tqdm(total=len(list(validation_data.iterrows()))) as pbar:\n",
    "    download_row = partial(progressive_download_test2, p=pbar)\n",
    "    pool.map( download_row, [(index, row) for index, row in validation_data.head(10).iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "pool = mp.Pool(processes=(mp.cpu_count()-2))\n",
    "tqdm.pandas(desc=\"processing in progress ... %d\" %(mp.cpu_count()))\n",
    "\n",
    "with tqdm(total=len(list(validation_data.iterrows()))) as pbar:\n",
    "    download_row = partial(progressive_download_photo, pbar)\n",
    "    pool.map( download_row, [(index, row) for index, row in validation_data.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas(desc=\"processing in progress ...\")\n",
    "\n",
    "with tqdm(total=len(list(validation_data.iterrows()))) as pbar:\n",
    "    for index, row in validation_data.iterrows():\n",
    "        image_name = row['image'].rsplit('/', 1)\n",
    "        download_photo(img_url='http:' + row['image'], group_type='valid', category=row['caption'], filename= \"%d.%s\" % (index, image_name[1]))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm.pandas(desc=\"processing in progress ...\")\n",
    "\n",
    "# train_data.progress_apply(lambda row: download_photo(img_url='http:' + row['image'], group_type='test', category=row['caption'], filename= row['image'].rsplit('/', 1)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.progress_apply(lambda x: download_image_of(x, 'train'))\n",
    "\n",
    "for index, row in train_data.iterrows():\n",
    "    image_name = row['image'].rsplit('/', 1)\n",
    "    download_photo(img_url='http:' + row['image'], group_type='test', category=row['caption'], filename= \"%d.%s\" % (index, image_name[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
